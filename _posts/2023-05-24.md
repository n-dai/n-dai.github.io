# Resolving the issues 
I realised that perhaps I am not meant to use all 60,000 images, but to use these images to form the training and validation set. I decided to go for a validation ratio of 20%. Therefore I will have 600 fake, and 600 real images in the training set, and 120 fake, and 120 images in the validation set.
Upon reorganising my folders to contain these images, I immediately noticed an increase in speed. Right now I am running it with the resnet34 architecture, however in future iterations, I will be experimenting with DenseNet, ResNetXt and VGG.
Resnet's approach to deep learning, is to stack additional layers in Deep Neural Networks, to improve the  accuracy and performance. The reason for adding more layers, is that these layers progressively learn more complex features. In the context of image identification, the initial layer may learn to detect edges for example, and then the second layer might learn to identify textures and so on.
DenseNet is different, in the fact that it obtain additional inputs from the previous layers, and then uses this to pass on its unique feature maps to all future layers.
